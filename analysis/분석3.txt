  세부 분석

  1. batch_size 영향 분석 (4-GPU 환경)

  batch_size를 16과 32로 설정했을 때의 성능을 request_rate별로 직접 비교해 보겠습니다.


  ┌──────────────┬────────────┬────────────────────┬─────────────────────────┬───────────────┬─────────────────────────┐
  │ Request Rate │ Batch Size │ Avg Req Throughput │ % Change                │ Avg TTFT (ms) │ % Change                │
  ├──────────────┼────────────┼────────────────────┼─────────────────────────┼───────────────┼─────────────────────────┤
  │ 20           │ 16         │ 16.60              │ \multirow{2}{}{+0.06%*} │ 83.38         │ \multirow{2}{}{-0.66%*} │
  │              │ 32         │ 16.61              │                         │ 82.83         │                         │
  │ 40           │ 16         │ 27.46              │ \multirow{2}{}{+0.04%*} │ 97.59         │ \multirow{2}{}{-0.56%*} │
  │              │ 32         │ 27.47              │                         │ 97.04         │                         │
  │ 60           │ 16         │ 34.03              │ \multirow{2}{}{-0.03%*} │ 120.67        │ \multirow{2}{}{-4.32%*} │
  │              │ 32         │ 34.02              │                         │ 115.46        │                         │
  └──────────────┴────────────┴────────────────────┴─────────────────────────┴───────────────┴─────────────────────────┘


  네, 제공해주신 최종 요약표를 바탕으로 batch_size 효과까지 포함한 종합적인 분석을 해드리겠습니다.

  결론 요약

   * 처리량(Throughput) 관점: batch_size를 32로 늘렸을 때의 처리량 향상은 0.06% 수준으로, 이는 측정 오차 범위 내에 있는 무시할 수 있는 변화입니다.
   * 응답 시간(Latency) 관점: batch_size를 32로 늘렸을 때 TTFT가 약간 감소하는 경향이 보이지만, 가장 큰 변화를 보인 60 req/s에서도 약 5ms (4.32%) 감소에 그쳤습니다. 이는 사용자 경험에 큰 영향을 줄 만한 수준은 아닙니다.

  결론: 현재 부하 수준(<= 60 req/s)에서는 batch_size를 16 이상으로 늘리는 것이 성능에 거의 아무런 이점을 주지 못합니다. 이는 시스템이 아직 포화 상태가 아니어서, 16개 이상의 요청을 한 번에 처리할 만큼의 대기열이 형성되지 않기 때문입니다.

  2. Latency Breakdown (TTFT vs TPOT) 재해석

   * TTFT (첫 토큰 지연 시간):
       * 1-GPU: request_rate가 10 -> 20으로 갈 때 90ms에서 6714ms로 폭증합니다.
       * 4-GPU: request_rate가 10 -> 60으로 증가하는 동안 65ms에서 120ms로 매우 완만하게 증가합니다.
       * 인사이트: 4-GPU 시스템은 높은 부하에서도 Prefill 단계를 매우 효율적으로 처리하여, 사용자의 초기 대기 시간을 획기적으로 줄여줍니다.

   1. GPU 확장성은 명확함: GPU를 1개에서 4개로 늘렸을 때, 시스템의 최대 처리량은 약 2.5배 (13.6 req/s → 34 req/s) 향상되었으며, 높은 부하에서도 응답 시간을 매우 낮고 안정적으로 유지했습니다.
   2. Batch Size 효과는 미미함: 현재 부하 수준(최대 60 req/s)에서는, 4-GPU 환경에서 batch_size를 16에서 32로 늘리는 것이 성능에 거의 아무런 영향을 주지 못했습니다. 두 설정 간의 처리량 및 응답 시간 차이는 1% 미만으로, 측정 오차 범위 내에 있습니다.
   3. 현재 병목 지점: 4-GPU 시스템의 경우, request_rate가 60일 때에도 아직 시스템이 완전히 포화되지 않았을 가능성이 있습니다. 처리량이 계속 증가하고 있고, 응답 시간(TTFT)이 120ms 수준으로 매우 안정적이기 때문입니다. 진정한 한계는 초당 60개 요청보다 
      더 높은 지점에 있을 것으로 보입니다.

  ---

  세부 분석

  1. Batch Size 효과 분석 (4-GPU 환경)

  batch_size 16과 32의 성능을 직접 비교해 보겠습니다.

   * TPOT (출력 토큰당 시간):
       * 1-GPU: 시스템이 포화 상태에 빠지자, TPOT 역시 38ms에서 약 69ms로 거의 두 배 증가합니다. 이는 시스템 전체에 과부하가 걸려 디코딩 단계까지 영향을 미쳤음을 의미합니다.
       * 4-GPU: request_rate가 10 -> 60으로 증가하는 동안 28ms에서 47ms로 점진적으로 증가합니다.
       * 인사이트: 4-GPU 시스템은 디코딩 속도 역시 더 안정적으로 유지합니다. 부하가 증가함에 따라 TPOT가 약간씩 늘어나는 것은, 더 많은 동시 요청을 관리하기 위한 스케줄링 오버헤드가 증가하기 때문으로 해석할 수 있습니다.

  ---

  최종 종합 결론 및 다음 단계 제언

  이 실험은 vLLM의 Data Parallelism이 높은 부하 상황에서의 안정성과 처리량 확보에 매우 효과적임을 성공적으로 증명했습니다. 하지만 4-GPU 시스템의 진정한 한계점을 찾지는 못했습니다.

  더 깊은 인사이트를 위한 다음 실험 제언:


  ┌──────────────┬────────────────────┬────────────────────┬──────────┬──────────────┬──────────────┬──────────┐
  │ Request Rate │ Throughput (BS=16) │ Throughput (BS=32) │ 차이 (%) │ TTFT (BS=16) │ TTFT (BS=32) │ 차이 (%) │
  ├──────────────┼────────────────────┼────────────────────┼──────────┼──────────────┼──────────────┼──────────┤
  │ 10           │ 9.23               │ 9.22               │ -0.1%    │ 65.12        │ 66.24        │ +1.7%    │
  │ 20           │ 16.60              │ 16.61              │ +0.06%   │ 83.38        │ 82.83        │ -0.7%    │
  │ 30           │ 22.63              │ 22.59              │ -0.2%    │ 90.09        │ 91.12        │ +1.1%    │
  │ 40           │ 27.46              │ 27.47              │ +0.04%   │ 97.59        │ 97.04        │ -0.6%    │
  │ 50           │ 31.21              │ 31.24              │ +0.1%    │ 105.22       │ 106.25       │ +1.0%    │
  │ 60           │ 34.03              │ 34.02              │ -0.03%   │ 120.67       │ 115.46       │ -4.3%    │
  └──────────────┴────────────────────┴────────────────────┴──────────┴──────────────┴──────────────┴──────────┘


   1. 4-GPU 포화점 탐색: gpu_counts를 [4]로 고정하고, request_rate를 [60, 80, 100, 120, ...] 와 같이 훨씬 더 높은 값으로 설정하여 4-GPU 시스템의 한계점을 찾습니다.
   2. 최적의 `batch_size` 찾기: 위 실험을 batch_size 16, 32, 64에 대해 각각 진행합니다. 4-GPU 시스템이 포화 상태에 가까워지면, batch_size를 늘리는 것이 처리량을 더 끌어올리는지, 아니면 오히려 오버헤드를 발생시켜 성능을 저하시키는지 확인할 수
      있습니다.

   * 처리량(Throughput): batch_size를 32로 늘렸을 때의 처리량 차이는 모든 부하 구간에서 ±0.2% 이내입니다. 이는 성능 차이가 거의 없다고 봐도 무방합니다.
   * 응답 시간(TTFT): request_rate가 60일 때 batch_size=32가 약 4.3% 더 빨랐던 것을 제외하면, 나머지 구간에서는 차이가 ±2% 이내로 매우 미미합니다.

  분석: 이 데이터는 "현재 부하 수준에서는 batch_size를 늘리는 것이 의미 있는 성능 향상을 가져오지 않는다"는 이전의 가설을 명확하게 뒷받침합니다. 시스템이 아직 포화 상태에 도달하지 않았기 때문에, 더 큰 배치를 처리할 기회가 없어 batch_size의 이점을
  활용하지 못하는 것입니다.

  2. Latency Breakdown 심층 분석 (TTFT vs. TPOT)

   * 1-GPU: request_rate가 10에서 20으로 넘어갈 때, TTFT(첫 토큰 시간) 는 90ms에서 6714ms로 폭증했지만, TPOT(토큰당 생성 시간) 는 38.8ms에서 69.8ms로 약 2배 증가하는 데 그쳤습니다.
       * 인사이트: 이는 시스템이 과부하에 걸렸을 때, 대부분의 시간이 요청이 대기열에서 기다리는 데(TTFT에 포함됨) 소요되고, 일단 처리가 시작되면 토큰 생성 속도 자체는 비교적 안정적으로 유지됨을 보여줍니다.

   * 4-GPU: request_rate가 10에서 60으로 증가하는 동안, TTFT는 65ms에서 120ms로 점진적으로 증가했지만, TPOT는 28.7ms에서 47.5ms로 함께 증가했습니다.
       * 인사이트: 4-GPU 시스템은 대기열을 효과적으로 관리하여 TTFT의 폭증을 막고 있습니다. 하지만 부하가 높아짐에 따라 각 GPU가 더 많은 시퀀스를 동시에 처리하게 되면서, 개별 시퀀스의 토큰 생성 속도(TPOT)는 약간씩 느려지는 것을
✦  볼 수 있습니다. 이는 GPU 리소스 경쟁으로 인한 자연스러운 현상입니다.

  ---

  최종 결론 및 다음 실험 제언

  이 실험은 vLLM의 확장성과 batch_size의 효과를 이해하는 데 매우 중요한 데이터를 제공했습니다.

   * 확장성 확인: GPU를 추가하면 높은 부하를 처리하는 능력이 크게 향상됩니다.
   * Batch Size의 조건부 효과: batch_size는 시스템이 포화 상태에 가까워져야만 그 효과가 나타납니다. 현재 실험에서는 4-GPU 시스템의 한계에 도달하지 못했기 때문에 batch_size의 효과를 관찰할 수 없었습니다.

  다음 단계 제언:

  만약 4-GPU 시스템의 진정한 한계와 최적의 batch_size를 찾고 싶다면, 다음과 같은 추가 실험을 설계할 수 있습니다.

   1. 4-GPU 포화점 탐색: gpu_counts를 [4]로 고정하고, request_rates를 [60, 80, 100, 120, ...] 와 같이 더 높은 값으로 설정하여 4-GPU 시스템이 언제 포화되는지 확인합니다.
   2. 포화점 근처에서 Batch Size 비교: 4-GPU의 포화점이 예를 들어 100 req/s로 확인되었다면, request_rate를 100으로 고정한 상태에서 batch_size를 [16, 32, 64, 128] 등으로 변경하며 어떤 batch_size가 가장 높은 처리량을 보이는지 비교합니다.

  이러한 추가 실험을 통해 시스템의 최대 성능을 끌어내는 최적의 파라미터를 찾을 수 있을 것입니다.