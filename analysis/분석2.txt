결론 요약

이 1-GPU 시스템의 포화점(Saturation Point)은 초당 요청 수(request_rate)가 10에서 20 사이에 있습니다. 시스템이 안정적으로 처리할 수 있는 최대 처리량(Max 
Throughput)은 약 13.7 req/s이며, 이 이상의 부하가 가해지면 시스템은 요청을 감당하지 못하고 응답 시간(Latency)이 기하급수적으로 늘어납니다.

---

세부 분석: 데이터가 말해주는 이야기

이 표를 해석하는 핵심은 "주어진 부하(request_rate)"와 "실제 처리량(request_throughput)", 그리고 "응답 시간(mean_ttft_ms)" 사이의 관계를 보는 것입니다.

1. 처리량의 한계 (Throughput Plateau)

* `request_rate`가 10일 때: 시스템은 주어진 부하 10 req/s를 거의 다 처리해내는 9.11 req/s의 성능을 보여줍니다. 이 구간에서는 시스템이 안정적입니다.
* `request_rate`가 20으로 증가하자: 시스템은 12.24 req/s밖에 처리하지 못합니다. 즉, 20개의 요청이 쏟아져 들어왔지만, 시스템은 약 12개만 처리하고 나머지는
    제대로 소화하지 못하기 시작했다는 첫 번째 신호입니다.
* `request_rate`가 20 이상일 때: 부하를 30, 40, 60으로 계속 늘려도, 실제 처리량은 12.24에서 13.68 req/s 사이에서 거의 정체됩니다. 이것이 바로 이 시스템의
    성능이 한계에 도달했다는 명백한 증거입니다. 더 많은 일을 시켜도 더 이상 일을 해내지 못하는 상태, 즉 포화 상태에 빠진 것입니다.
* total_token_throughput (초당 총 토큰 처리량) 역시 약 4100 tok/s 근처에서 한계에 도달하는 동일한 패턴을 보여줍니다.

2. 응답 시간의 폭증 (Latency Explosion)

처리량보다 더 극적인 변화는 응답 시간에서 나타납니다.

* `request_rate`가 10일 때: 평균 첫 토큰 응답 시간(mean_ttft_ms)은 87.58ms (0.08초)로 매우 빠르고 쾌적합니다.
* `request_rate`가 20으로 증가하자: 응답 시간이 6899ms (약 6.9초)로 약 80배 폭증합니다.
* `request_rate`가 20 이상일 때: 응답 시간은 계속해서 늘어나 60 req/s에서는 17.9초에 달합니다.

이는 시스템이 처리할 수 있는 양보다 많은 요청이 들어오자, 요청들이 대기열(queue)에서 하염없이 기다리게 되면서 발생하는 전형적인 "지연 시간 폭증"
현상입니다.

비유: 마트 계산대

이 현상은 마트 계산대에 비유할 수 있습니다.
* 10 req/s: 계산대에 손님이 10명씩 도착합니다. 계산원은 여유롭게 모든 손님을 처리합니다. (낮은 Latency)
* 20 req/s: 갑자기 손님이 20명씩 몰려옵니다. 계산원은 12~13명밖에 처리하지 못하고, 나머지 손님들은 줄을 서서 길게 기다리기 시작합니다. (Latency 폭증,
    Throughput 정체 시작)
* 60 req/s: 손님이 60명씩 몰려와도 계산원은 여전히 13명 정도밖에 처리하지 못합니다. 계산대 뒤의 줄은 상상할 수 없을 정도로 길어집니다. (Latency 최악,
    Throughput 한계 도달)

---

최종 결론 및 다음 단계

* 1-GPU의 명확한 한계: 현재 시스템에서 GPU 1개는 약 13.7 req/s의 처리량을 감당할 수 있으며, 이 이상의 부하에서는 성능 저하가 심각합니다.
* 의미 있는 확장성 테스트의 기반: 이제 우리는 GPU 4개의 성능을 제대로 비교할 수 있는 기준점을 찾았습니다. GPU 4개 환경에서 request_rate를 20, 40, 60, 
    80... 과 같이 1-GPU의 한계를 넘어서는 높은 값으로 설정하여 실험을 진행하면, 4-GPU 시스템이 실제로 얼마나 더 높은 처리량을 감당할 수 있는지, 즉 진정한 
    확장성을 측정할 수 있게 됩니다.

이 분석 결과를 바탕으로, 4-GPU 환경에 대한 확장성 테스트를 다시 설계하여 실행하는 것을 추천합니다.